ğŸ  [**Inicio**](../Readme.md) â¡ï¸ / ğŸ“– `SesiÃ³n 05`

<div align="center">
    <img src="Imagenes/S05_Bedu.png" alt="Sesion_05">
</div>

## ğŸ¯ Objetivo

âš’ï¸ Comprender y aplicar distribuciones muestrales y tÃ©cnicas de Bootstrap para estimar la precisiÃ³n de las estadÃ­sticas de la muestra, calcular errores estÃ¡ndar y entender su importancia en la inferencia estadÃ­stica, determinar intervalos de confianza para evaluar la precisiÃ³n de las estimaciones, y aplicar tÃ©cnicas de validaciÃ³n cruzada para evaluar la efectividad de los modelos predictivos.

---

ğŸ“˜ Material del prework: Antes de comenzar con los ejercicios de esta sesiÃ³n, recordemos que en el material de prework hemos cubierto los fundamentos teÃ³ricos que aplicaremos hoy. A lo largo de esta sesiÃ³n, pondremos en prÃ¡ctica estos conceptos mediante una serie de ejercicios y retos diseÃ±ados para reforzar y validar nuestro entendimiento. ğŸ”¥Â¡Vamos a comenzar!ğŸ”¥

---

## ğŸ“‚ Temas de la sesiÃ³n...


### ğŸ“– Error estÃ¡ndar e intervalos de confianza
El error estÃ¡ndar es una medida de la variabilidad o dispersiÃ³n de una estadÃ­stica muestral, como la media, con relaciÃ³n a la verdadera media poblacional. Se utiliza para cuantificar la precisiÃ³n de la estimaciÃ³n de la estadÃ­stica de muestra y se calcula como la desviaciÃ³n estÃ¡ndar de la distribuciÃ³n muestral.

El intervalo de confianza da una aproximaciÃ³n de los valores entre los cuales se encuentra el valor de un parÃ¡metro poblacional con un determinado nivel de confianza. Los intervalos de confianza mÃ¡s habituales tienen un nivel de confianza del 95% o del 99%.

#### ğŸ“œ **[Ejemplo 01: Error estÃ¡ndar e intervalos de confianza](Ejemplo-01/Readme.md)**

---

### ğŸ“– Distribuciones muestrales y Bootstrap
TambiÃ©n llamada distribuciÃ³n de muestreo describe la variabilidad de una estadÃ­stica de muestra, como la media o la proporciÃ³n, a travÃ©s de mÃºltiples muestras tomadas de la misma poblaciÃ³n. 

El mÃ©todo Bootstrap es una tÃ©cnica de remuestreo que te permite estimar la precisiÃ³n de las estadÃ­sticas de muestra, como la media o la mediana, sin hacer suposiciones sobre la distribuciÃ³n de la poblaciÃ³n.

#### ğŸ“œ **[Ejemplo 02: Distribuciones muestrales y Bootstrap](Ejemplo-02/Readme.md)**
#### ğŸ”¥ **[Reto 01:  AnÃ¡lisis de la distribuciÃ³n de recursos naturales](Reto-01/Readme.md)**

---

### ğŸ“– TÃ©cnicas de evaluaciÃ³n de modelos
La evaluaciÃ³n de modelos predictivos es el proceso de medir y analizar el rendimiento de un modelo para asegurarse de que sus predicciones sean precisas y confiables. Esto quiere decir que el modelo es preciso, no sesgado y capaz de generalizar bien a datos nuevos.

**PrecisiÃ³n:** ProporciÃ³n de verdaderos positivos sobre el total de predicciones positivas. Indica cuÃ¡n exactas son las predicciones positivas del modelo.

**Recall (Sensibilidad):** ProporciÃ³n de verdaderos positivos sobre el total de positivos reales. Mide la capacidad del modelo para identificar correctamente todas las instancias positivas. 

**F1 â€“ score:** Media armÃ³nica de precisiÃ³n y recall.  Ofrece un balance entre ambas mÃ©tricas, siendo Ãºtil cuando necesitas considerar tanto la precisiÃ³n como la sensibilidad del modelo

#### ğŸ“œ **[Ejemplo 03: TÃ©cnicas de evaluaciÃ³n de modelos](Ejemplo-03/Readme.md)**
#### ğŸ”¥ **[Reto 02:  EvaluaciÃ³n de modelos de predicciÃ³n de recursos hÃ­dricos](Reto-02/Readme.md)**

---

### ğŸ“– ValidaciÃ³n cruzada
Es una tÃ©cnica utilizada para evaluar la capacidad predictiva de un modelo y evitar el sobreajuste. Los mÃ©todos mÃ¡s comunes de validaciÃ³n cruzada son:

**K-Fold Cross-Validation:** Divide los datos en k subconjuntos (folds) de tamaÃ±o aproximadamente igual. El modelo se entrena k veces, cada vez utilizando k-1 folds para el entrenamiento y el fold restante para la evaluaciÃ³n.

**Leave-One-Out Cross-Validation (LOOCV):** Cada observaciÃ³n se utiliza una vez como conjunto de prueba mientras que el resto se utiliza como conjunto de entrenamiento. Esto resulta en tantas iteraciones como observaciones en el conjunto de datos.

**Stratified K-Fold Cross-Validation:** Similar a k-fold cross-validation, pero se asegura de que cada fold tenga la misma proporciÃ³n de clases que el conjunto de datos original.

#### ğŸ“œ **[Ejemplo 04: MÃ©todos de validaciÃ³n cruzada](Ejemplo-04/Readme.md)**

---

â¬…ï¸ [**Anterior**](../Sesion-04/Readme.md) | [**Siguiente**](../Sesion-06/Readme.md)â¡ï¸