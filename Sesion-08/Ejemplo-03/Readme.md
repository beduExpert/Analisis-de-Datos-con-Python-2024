üè† [**Inicio**](../../Readme.md) ‚û°Ô∏è / üìñ [**Sesi√≥n 08**](../Readme.md) ‚û°Ô∏è / üìù `Ejemplo 03: Matriz de confusi√≥n para evaluaci√≥n de modelos`

## üéØ Objetivo

Aprender a utilizar la **Matriz de Confusi√≥n** y otras m√©tricas para evaluar el rendimiento de un modelo de clasificaci√≥n. En este caso, utilizaremos un dataset de transacciones de tarjetas de cr√©dito para predecir si una transacci√≥n es fraudulenta o no, y analizaremos la precisi√≥n del modelo utilizando la matriz de confusi√≥n, exactitud, precisi√≥n, sensibilidad, especificidad y F1 score.

---

## üöÄ Comencemos

La **Matriz de Confusi√≥n** es una herramienta utilizada para evaluar el rendimiento de un modelo de clasificaci√≥n, mostrando el n√∫mero de predicciones correctas e incorrectas categorizadas por cada clase. Adem√°s, podemos calcular m√©tricas como la exactitud, precisi√≥n, sensibilidad, especificidad y F1 score para obtener una evaluaci√≥n m√°s detallada del modelo. En este ejemplo, utilizaremos un dataset de transacciones de tarjetas de cr√©dito para analizar c√≥mo estas m√©tricas pueden ayudar a evaluar el desempe√±o del modelo de regresi√≥n log√≠stica en la detecci√≥n de fraudes. Utilizaremos el archivo [Ejemplo_03_Credit_Card_Fraud_Dataset.csv](../../Datasets/S08/Ejemplo_03_Credit_Card_Fraud_Dataset.csv).

---

### üõ†Ô∏è **Aplicaci√≥n de la matriz de confusi√≥n y m√©tricas de evaluaci√≥n**

Sigue los siguientes pasos para aplicar la matriz de confusi√≥n y calcular las m√©tricas de evaluaci√≥n al dataset de detecci√≥n de fraudes:

1. **Instalaci√≥n de las bibliotecas necesarias:** Aseg√∫rate de tener instaladas las bibliotecas necesarias para realizar el an√°lisis. Si no las tienes, inst√°lalas con el siguiente comando:

    ```bash
    !pip install pandas numpy scikit-learn matplotlib seaborn
    ```

2. **Importaci√≥n de las bibliotecas:** Importa las bibliotecas que vas a utilizar:

    ```python
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
    import matplotlib.pyplot as plt
    import pandas as pd
    import numpy as np
    ```

3. **Carga y exploraci√≥n del conjunto de datos:** Carga el dataset de detecci√≥n de fraudes y explora las primeras filas para familiarizarte con los datos:

    ```python
    # Cargar el conjunto de datos
    df = pd.read_csv('Ejemplo_03_Credit_Card_Fraud_Dataset.csv')  # Ajusta la ruta al archivo seg√∫n tu entorno de trabajo.

    # Mostrar las primeras filas del DataFrame
    df.head()
    ```

4. **Preprocesamiento de datos:** Selecciona las columnas relevantes para el an√°lisis:

    ```python
    # Seleccionar las columnas relevantes para el an√°lisis
    X = df[['Transaction Amount', 'Transaction Month', 'Transaction Year', 'Transaction Day', 
            'Transaction Hour', 'Transaction Minute', 'Transaction Second', 'Merchant ID']]
    y = df['Fraudulent Flag']
    ```

5. **Divisi√≥n del conjunto de datos:** Divide el conjunto de datos en conjuntos de entrenamiento y prueba:

    ```python
    # Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    ```

6. **Aplicaci√≥n de la regresi√≥n log√≠stica:** Aplica el algoritmo de regresi√≥n log√≠stica a los datos de entrenamiento:

    ```python
    # Inicializar el modelo de Regresi√≥n Log√≠stica
    logreg = LogisticRegression(max_iter=1000)

    # Ajustar el modelo a los datos de entrenamiento
    logreg.fit(X_train, y_train)

    # Realizar predicciones con el conjunto de prueba
    y_pred = logreg.predict(X_test)

    # Obtener el score del modelo en los datos de prueba
    score = logreg.score(X_test, y_test)
    print(f"Precisi√≥n del modelo: {score:.2f}")
    ```
    ```plaintext
    üõçÔ∏è Precisi√≥n del modelo: 0.51
    ```
    <!-- Resumen -->
    La precisi√≥n del modelo es del 51%, lo que indica que el modelo clasifica correctamente aproximadamente la mitad de las transacciones.

    <br>

7. **Generar y visualizar la matriz de confusi√≥n:** Utiliza la matriz de confusi√≥n para evaluar el rendimiento del modelo:

    ```python
    # Crear la matriz de confusi√≥n
    cm = confusion_matrix(y_test, y_pred)

    # Visualizar la matriz de confusi√≥n con tama√±o ajustado
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Fraud', 'Fraud'])
    fig, ax = plt.subplots(figsize=(10, 8))  # Ajustar el tama√±o de la figura aqu√≠
    disp.plot(cmap='Blues', ax=ax)  # Pasar el objeto ax al m√©todo plot
    plt.ylabel('Realidad', fontsize=15, y=0.5)
    plt.xlabel('Estimado por el modelo', fontsize=15)
    plt.show()
    ```

    <details>
        <summary><b>‚ú®Haz clic aqu√≠ para ver la imagen‚ú®</b></summary>
        <div align="center">
            <img src="../Imagenes/Ejemplo_03_Imagen_01.png" alt="Confusion Matrix" width="50%">
        </div>
    </details>

    <br>

8. **Calcular m√©tricas de evaluaci√≥n:** Calcula la exactitud, precisi√≥n, sensibilidad, especificidad y F1 score del modelo:

    ```python
    # Generar el informe de clasificaci√≥n
    report = classification_report(y_test, y_pred, target_names=['No Fraud', 'Fraud'], output_dict=True)

    # Convertir el informe a un DataFrame
    report_df = pd.DataFrame(report).transpose()
    report_df.head()
    ```
    |                | precision | recall    | f1-score  | support   |
    |----------------|-----------|-----------|-----------|-----------|
    | **No Fraud**   | 0.510460  | 0.410774  | 0.455224  | 297.000000 |
    | **Fraud**      | 0.515235  | 0.613861  | 0.560241  | 303.000000 |
    | **accuracy**   | 0.513333  | 0.513333  | 0.513333  | 0.513333   |
    | **macro avg**  | 0.512848  | 0.512318  | 0.507732  | 600.000000 |
    | **weighted avg**| 0.512872 | 0.513333  | 0.508258  | 600.000000 |


    Esto producir√° un informe de clasificaci√≥n que incluye las siguientes m√©tricas:

    - **Exactitud (Accuracy)**: Proporci√≥n de predicciones correctas sobre el total de predicciones.
    - **Precisi√≥n (Precision)**: Proporci√≥n de verdaderos positivos sobre el total de predicciones positivas. Indica cu√°n precisas son las predicciones de la clase positiva.
    - **Sensibilidad (Recall o Sensitivity)**: Proporci√≥n de verdaderos positivos sobre el total de verdaderos positivos y falsos negativos. Indica cu√°ntos casos positivos reales fueron identificados correctamente.
    - **Especificidad (Specificity)**: Proporci√≥n de verdaderos negativos sobre el total de verdaderos negativos y falsos positivos. Indica cu√°ntos casos negativos reales fueron identificados correctamente.
    - **F1 Score**: Media arm√≥nica de la precisi√≥n y la sensibilidad. Proporciona un equilibrio entre precisi√≥n y sensibilidad.

---

### üìâ **Interpretaci√≥n de los resultados**

De acuerdo a los resultados obtenidos, podemos interpretar lo siguiente:

- **Exactitud (Accuracy)**: El modelo tiene una exactitud de 51.33%, lo que significa que clasifica correctamente un poco m√°s de la mitad de las transacciones. Este rendimiento es solo ligeramente mejor que un modelo de azar (50%).

- **Precisi√≥n (Precision)**: 
  - Para "No Fraud", la precisi√≥n es de 51.05%, indicando que poco m√°s de la mitad de las predicciones de no fraude son correctas.
  - Para "Fraud", la precisi√≥n es de 51.52%, sugiriendo un comportamiento similar para la detecci√≥n de fraudes.

- **Sensibilidad (Recall)**:
  - Para "No Fraud", la sensibilidad es de 41.08%, lo que indica que el modelo detecta menos de la mitad de las transacciones no fraudulentas correctamente.
  - Para "Fraud", la sensibilidad es de 61.39%, lo que muestra que el modelo es mejor detectando fraudes que identificando transacciones leg√≠timas.

- **F1 Score**: 
  - Los F1 scores son de 45.52% para "No Fraud" y 56.02% para "Fraud", reflejando un balance entre precisi√≥n y sensibilidad. El modelo es moderadamente mejor en la detecci√≥n de fraudes.

- **Promedios Globales**:
  - **Macro Avg**: Este promedio toma en cuenta las m√©tricas de ambas clases de manera equitativa, independientemente del n√∫mero de casos en cada clase. Los valores de precisi√≥n, sensibilidad y F1 score rondan el 51%, lo que indica un rendimiento bajo del modelo.
  - **Weighted Avg**: Este promedio pondera las m√©tricas de acuerdo al n√∫mero de muestras en cada clase. Dado que los valores ponderados son similares a los valores de cada clase, se sugiere que el dataset no est√° fuertemente desbalanceado.

El modelo muestra un rendimiento limitado, especialmente en la detecci√≥n de transacciones no fraudulentas, y apenas supera un modelo aleatorio. Para mejorar la detecci√≥n de fraudes, ser√≠a √∫til considerar t√©cnicas avanzadas y ajustes adicionales del modelo.

Otro tipo de interpretaci√≥n visual podria ser la siguiente imagen:

<details>
    <summary><b>‚ú®Haz clic aqu√≠ para ver la imagen‚ú®</b></summary>
    <div align="center">
        <img src="../Imagenes/Ejemplo_03_Imagen_02.png" alt="Confusion Matrix" width="50%">
    </div>
</details>

---

### üí° **¬øSab√≠as que?...**

### Modelos de clasificaci√≥n que utilizan la matriz de confusi√≥n

La matriz de confusi√≥n se puede utilizar con cualquier tipo de modelo de clasificaci√≥n, incluyendo pero no limitado a:

1. **Regresi√≥n Log√≠stica**: Es un modelo de clasificaci√≥n supervisada utilizado para predecir resultados binarios.
2. **√Årboles de Decisi√≥n**: Modelos que utilizan una estructura de √°rbol para tomar decisiones y clasificar datos.
3. **Random Forest**: Un conjunto de √°rboles de decisi√≥n que mejora la precisi√≥n de la clasificaci√≥n mediante la combinaci√≥n de m√∫ltiples √°rboles.
4. **M√°quinas de Vectores de Soporte (SVM)**: Modelos que buscan un hiperplano que mejor separe las clases en un espacio de caracter√≠sticas de alta dimensi√≥n.
5. **K-Nearest Neighbors (KNN)**: Modelo basado en la proximidad de un punto a sus vecinos m√°s cercanos en un espacio de caracter√≠sticas.

---

‚¨ÖÔ∏è [**Anterior**](../Readme.md) | [**Siguiente**](../Reto-02/Readme.md) ‚û°Ô∏è